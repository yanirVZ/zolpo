import time
import json
import schedule
import sys
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys

# ×¤×¨×˜×™ ×”××ª×¨
URL = "https://url.publishedprices.co.il/file"
COOKIES_PATH = "cookies.json"
OUTPUT_PATH = "valid_links_osherad.txt"  # ×¢×“×›×•×Ÿ ×©× ×”×§×•×‘×¥
USER_NAME = "osherad"  # ×©× ×”××©×ª××© ×©×œ ×™×•×—× × ×•×£

# ×¤×•× ×§×¦×™×” ×œ×”×•×¨×“×ª ×”-cookies ×©×©××•×¨×™×
def load_cookies(driver):
    try:
        with open(COOKIES_PATH, "r") as f:
            cookies = json.load(f)
        for cookie in cookies:
            driver.add_cookie(cookie)
        print("ğŸª Cookies loaded.")
    except Exception as e:
        print(f"âš ï¸ Couldn't load cookies: {e}")

# ×”×’×“×¨×ª ×”×“×¨×™×™×‘×¨ ×©×œ Selenium ×‘-Headless Mode (×œ×œ× ×“×¤×“×¤×Ÿ ×’×¨×¤×™)
def setup_driver():
    options = Options()
    options.add_argument("--ignore-certificate-errors")
    options.add_argument("--allow-insecure-localhost")
    options.add_argument("--headless")
    options.add_argument("--start-maximized")
    driver = webdriver.Chrome(options=options)
    return driver

# ×”×ª×—×‘×¨×•×ª ××•×˜×•××˜×™×ª ×œ××ª×¨
def login(driver):
    try:
        driver.get(URL)
        user_field = driver.find_element(By.ID, "username")
        password_field = driver.find_element(By.ID, "password")

        user_field.send_keys(USER_NAME)
        password_field.send_keys("")  # ××™×Ÿ ×¡×™×¡××”
        password_field.send_keys(Keys.RETURN)
        time.sleep(3)
        print("ğŸ”’ ×”×ª×—×‘×¨×•×ª ×”×•×©×œ××”.")
    except Exception as e:
        print(f"âš ï¸ ×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª: {e}")

# ×¤×•× ×§×¦×™×” ×œ×¡×§×¨×™×™×¤×™× ×’ ×©×œ ×”×§×™×©×•×¨×™×
def scrape_links():
    driver = setup_driver()

    login(driver)  # ×”×ª×—×‘×¨×•×ª ××•×˜×•××˜×™×ª

    try:
        load_cookies(driver)
        driver.refresh()
        time.sleep(5)
    except Exception as e:
        print(f"âš ï¸ Error loading cookies or refreshing: {e}")

    try:
        links = driver.find_elements(By.TAG_NAME, "a")
        valid = []

        for link in links:
            href = link.get_attribute("href")
            if href and href.endswith(".gz") and "Price" in href:
                valid.append(href)
                print(f"âœ… × ××¦× ×§×•×‘×¥: {href}")

        print(f"\nğŸ”— × ××¦××• {len(valid)} ×§×‘×¦×™×.")
        with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
            for line in valid:
                f.write(line + "\n")

    except Exception as e:
        print(f"âš ï¸ Error scraping links: {e}")

    driver.quit()
    print("âœ”ï¸ Task Completed Successfully")
    time.sleep(10)
    print("ğŸ›‘ ×”×ª×›× ×™×ª ×”×¡×ª×™×™××” ××•×˜×•××˜×™×ª.")
    sys.exit()

# ×”×’×“×¨×ª ××©×™××” ×©×ª×•×¤×¢×œ ×›×œ 24 ×©×¢×•×ª ×‘×©×¢×” 10:30 ×‘×‘×•×§×¨
def job():
    print("ğŸŒ… ×”×ª×—×œ×ª ×¡×§×¨×™×™×¤×™× ×’ ×‘-10:30 ×‘×‘×•×§×¨...")
    scrape_links()

# ×ª×–××•×Ÿ ×”××©×™××” ×œ×©×¢×” 10:30 ×‘×‘×•×§×¨
schedule.every().day.at("13:08").do(job)

# ×©××™×¨×” ×¢×œ ×”×¤×¢×œ×ª ×”×ª×•×›× ×™×ª ×›×œ ×”×–××Ÿ
if __name__ == "__main__":
    print("â³ ××ª×›× ×Ÿ ××ª ×”××©×™××” ×©×ª×•×¤×¢×œ ×›×œ ×™×•× ×‘×©×¢×” 10:30.")
    while True:
        try:
            schedule.run_pending()
            time.sleep(1)
        except KeyboardInterrupt:
            print("ğŸ”´ ××©×™××” ×‘×•×˜×œ×” ×™×“× ×™×ª.")
            break
